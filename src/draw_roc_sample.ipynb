{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>exp2_50 - train/precision</th>\n",
       "      <th>exp2_50 - train/precision__MIN</th>\n",
       "      <th>exp2_50 - train/precision__MAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.516613</td>\n",
       "      <td>0.516613</td>\n",
       "      <td>0.516613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>0.519200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0.517485</td>\n",
       "      <td>0.517485</td>\n",
       "      <td>0.517485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.518100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>0.522679</td>\n",
       "      <td>0.522679</td>\n",
       "      <td>0.522679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>0.522459</td>\n",
       "      <td>0.522459</td>\n",
       "      <td>0.522459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>0.519566</td>\n",
       "      <td>0.519566</td>\n",
       "      <td>0.519566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34</td>\n",
       "      <td>0.520002</td>\n",
       "      <td>0.520002</td>\n",
       "      <td>0.520002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38</td>\n",
       "      <td>0.519161</td>\n",
       "      <td>0.519161</td>\n",
       "      <td>0.519161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>43</td>\n",
       "      <td>0.524110</td>\n",
       "      <td>0.524110</td>\n",
       "      <td>0.524110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47</td>\n",
       "      <td>0.522728</td>\n",
       "      <td>0.522728</td>\n",
       "      <td>0.522728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>52</td>\n",
       "      <td>0.520757</td>\n",
       "      <td>0.520757</td>\n",
       "      <td>0.520757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>56</td>\n",
       "      <td>0.520694</td>\n",
       "      <td>0.520694</td>\n",
       "      <td>0.520694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>61</td>\n",
       "      <td>0.521628</td>\n",
       "      <td>0.521628</td>\n",
       "      <td>0.521628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>65</td>\n",
       "      <td>0.521609</td>\n",
       "      <td>0.521609</td>\n",
       "      <td>0.521609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>70</td>\n",
       "      <td>0.521551</td>\n",
       "      <td>0.521551</td>\n",
       "      <td>0.521551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>74</td>\n",
       "      <td>0.520563</td>\n",
       "      <td>0.520563</td>\n",
       "      <td>0.520563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>78</td>\n",
       "      <td>0.523598</td>\n",
       "      <td>0.523598</td>\n",
       "      <td>0.523598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>83</td>\n",
       "      <td>0.519241</td>\n",
       "      <td>0.519241</td>\n",
       "      <td>0.519241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>87</td>\n",
       "      <td>0.525595</td>\n",
       "      <td>0.525595</td>\n",
       "      <td>0.525595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>92</td>\n",
       "      <td>0.523484</td>\n",
       "      <td>0.523484</td>\n",
       "      <td>0.523484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>96</td>\n",
       "      <td>0.519299</td>\n",
       "      <td>0.519299</td>\n",
       "      <td>0.519299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>101</td>\n",
       "      <td>0.523295</td>\n",
       "      <td>0.523295</td>\n",
       "      <td>0.523295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>105</td>\n",
       "      <td>0.524829</td>\n",
       "      <td>0.524829</td>\n",
       "      <td>0.524829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>110</td>\n",
       "      <td>0.523355</td>\n",
       "      <td>0.523355</td>\n",
       "      <td>0.523355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>114</td>\n",
       "      <td>0.526088</td>\n",
       "      <td>0.526088</td>\n",
       "      <td>0.526088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>118</td>\n",
       "      <td>0.528503</td>\n",
       "      <td>0.528503</td>\n",
       "      <td>0.528503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>123</td>\n",
       "      <td>0.524531</td>\n",
       "      <td>0.524531</td>\n",
       "      <td>0.524531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Step  exp2_50 - train/precision  exp2_50 - train/precision__MIN  \\\n",
       "0      3                   0.516613                        0.516613   \n",
       "1      7                   0.519200                        0.519200   \n",
       "2     12                   0.517485                        0.517485   \n",
       "3     16                   0.518100                        0.518100   \n",
       "4     21                   0.522679                        0.522679   \n",
       "5     25                   0.522459                        0.522459   \n",
       "6     30                   0.519566                        0.519566   \n",
       "7     34                   0.520002                        0.520002   \n",
       "8     38                   0.519161                        0.519161   \n",
       "9     43                   0.524110                        0.524110   \n",
       "10    47                   0.522728                        0.522728   \n",
       "11    52                   0.520757                        0.520757   \n",
       "12    56                   0.520694                        0.520694   \n",
       "13    61                   0.521628                        0.521628   \n",
       "14    65                   0.521609                        0.521609   \n",
       "15    70                   0.521551                        0.521551   \n",
       "16    74                   0.520563                        0.520563   \n",
       "17    78                   0.523598                        0.523598   \n",
       "18    83                   0.519241                        0.519241   \n",
       "19    87                   0.525595                        0.525595   \n",
       "20    92                   0.523484                        0.523484   \n",
       "21    96                   0.519299                        0.519299   \n",
       "22   101                   0.523295                        0.523295   \n",
       "23   105                   0.524829                        0.524829   \n",
       "24   110                   0.523355                        0.523355   \n",
       "25   114                   0.526088                        0.526088   \n",
       "26   118                   0.528503                        0.528503   \n",
       "27   123                   0.524531                        0.524531   \n",
       "\n",
       "    exp2_50 - train/precision__MAX  \n",
       "0                         0.516613  \n",
       "1                         0.519200  \n",
       "2                         0.517485  \n",
       "3                         0.518100  \n",
       "4                         0.522679  \n",
       "5                         0.522459  \n",
       "6                         0.519566  \n",
       "7                         0.520002  \n",
       "8                         0.519161  \n",
       "9                         0.524110  \n",
       "10                        0.522728  \n",
       "11                        0.520757  \n",
       "12                        0.520694  \n",
       "13                        0.521628  \n",
       "14                        0.521609  \n",
       "15                        0.521551  \n",
       "16                        0.520563  \n",
       "17                        0.523598  \n",
       "18                        0.519241  \n",
       "19                        0.525595  \n",
       "20                        0.523484  \n",
       "21                        0.519299  \n",
       "22                        0.523295  \n",
       "23                        0.524829  \n",
       "24                        0.523355  \n",
       "25                        0.526088  \n",
       "26                        0.528503  \n",
       "27                        0.524531  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "precision_pth =\"C:\\\\Users\\\\A200274027\\\\vscode\\\\pix\\\\home\\\\playground\\\\ssl_sample\\\\outputs\\\\wanb_export\\\\denoised_sample\\\\exp20_50_precision.csv\"\n",
    "df_precision = pd.read_csv(precision_pth,delimiter=\",\")\n",
    "df_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>exp2_50 - train/recall</th>\n",
       "      <th>exp2_50 - train/recall__MIN</th>\n",
       "      <th>exp2_50 - train/recall__MAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.609100</td>\n",
       "      <td>0.609100</td>\n",
       "      <td>0.609100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.611810</td>\n",
       "      <td>0.611810</td>\n",
       "      <td>0.611810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0.606344</td>\n",
       "      <td>0.606344</td>\n",
       "      <td>0.606344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.605739</td>\n",
       "      <td>0.605739</td>\n",
       "      <td>0.605739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>0.616122</td>\n",
       "      <td>0.616122</td>\n",
       "      <td>0.616122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25</td>\n",
       "      <td>0.615171</td>\n",
       "      <td>0.615171</td>\n",
       "      <td>0.615171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>0.611106</td>\n",
       "      <td>0.611106</td>\n",
       "      <td>0.611106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34</td>\n",
       "      <td>0.609487</td>\n",
       "      <td>0.609487</td>\n",
       "      <td>0.609487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38</td>\n",
       "      <td>0.608666</td>\n",
       "      <td>0.608666</td>\n",
       "      <td>0.608666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>43</td>\n",
       "      <td>0.617653</td>\n",
       "      <td>0.617653</td>\n",
       "      <td>0.617653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47</td>\n",
       "      <td>0.616868</td>\n",
       "      <td>0.616868</td>\n",
       "      <td>0.616868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>52</td>\n",
       "      <td>0.613506</td>\n",
       "      <td>0.613506</td>\n",
       "      <td>0.613506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>56</td>\n",
       "      <td>0.618782</td>\n",
       "      <td>0.618782</td>\n",
       "      <td>0.618782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>61</td>\n",
       "      <td>0.615999</td>\n",
       "      <td>0.615999</td>\n",
       "      <td>0.615999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>65</td>\n",
       "      <td>0.613096</td>\n",
       "      <td>0.613096</td>\n",
       "      <td>0.613096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>70</td>\n",
       "      <td>0.609354</td>\n",
       "      <td>0.609354</td>\n",
       "      <td>0.609354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>74</td>\n",
       "      <td>0.614012</td>\n",
       "      <td>0.614012</td>\n",
       "      <td>0.614012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>78</td>\n",
       "      <td>0.615486</td>\n",
       "      <td>0.615486</td>\n",
       "      <td>0.615486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>83</td>\n",
       "      <td>0.607384</td>\n",
       "      <td>0.607384</td>\n",
       "      <td>0.607384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>87</td>\n",
       "      <td>0.619296</td>\n",
       "      <td>0.619296</td>\n",
       "      <td>0.619296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>92</td>\n",
       "      <td>0.620584</td>\n",
       "      <td>0.620584</td>\n",
       "      <td>0.620584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>96</td>\n",
       "      <td>0.616376</td>\n",
       "      <td>0.616376</td>\n",
       "      <td>0.616376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>101</td>\n",
       "      <td>0.620481</td>\n",
       "      <td>0.620481</td>\n",
       "      <td>0.620481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>105</td>\n",
       "      <td>0.619397</td>\n",
       "      <td>0.619397</td>\n",
       "      <td>0.619397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>110</td>\n",
       "      <td>0.611576</td>\n",
       "      <td>0.611576</td>\n",
       "      <td>0.611576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>114</td>\n",
       "      <td>0.619854</td>\n",
       "      <td>0.619854</td>\n",
       "      <td>0.619854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>118</td>\n",
       "      <td>0.623876</td>\n",
       "      <td>0.623876</td>\n",
       "      <td>0.623876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>123</td>\n",
       "      <td>0.620962</td>\n",
       "      <td>0.620962</td>\n",
       "      <td>0.620962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Step  exp2_50 - train/recall  exp2_50 - train/recall__MIN  \\\n",
       "0      3                0.609100                     0.609100   \n",
       "1      7                0.611810                     0.611810   \n",
       "2     12                0.606344                     0.606344   \n",
       "3     16                0.605739                     0.605739   \n",
       "4     21                0.616122                     0.616122   \n",
       "5     25                0.615171                     0.615171   \n",
       "6     30                0.611106                     0.611106   \n",
       "7     34                0.609487                     0.609487   \n",
       "8     38                0.608666                     0.608666   \n",
       "9     43                0.617653                     0.617653   \n",
       "10    47                0.616868                     0.616868   \n",
       "11    52                0.613506                     0.613506   \n",
       "12    56                0.618782                     0.618782   \n",
       "13    61                0.615999                     0.615999   \n",
       "14    65                0.613096                     0.613096   \n",
       "15    70                0.609354                     0.609354   \n",
       "16    74                0.614012                     0.614012   \n",
       "17    78                0.615486                     0.615486   \n",
       "18    83                0.607384                     0.607384   \n",
       "19    87                0.619296                     0.619296   \n",
       "20    92                0.620584                     0.620584   \n",
       "21    96                0.616376                     0.616376   \n",
       "22   101                0.620481                     0.620481   \n",
       "23   105                0.619397                     0.619397   \n",
       "24   110                0.611576                     0.611576   \n",
       "25   114                0.619854                     0.619854   \n",
       "26   118                0.623876                     0.623876   \n",
       "27   123                0.620962                     0.620962   \n",
       "\n",
       "    exp2_50 - train/recall__MAX  \n",
       "0                      0.609100  \n",
       "1                      0.611810  \n",
       "2                      0.606344  \n",
       "3                      0.605739  \n",
       "4                      0.616122  \n",
       "5                      0.615171  \n",
       "6                      0.611106  \n",
       "7                      0.609487  \n",
       "8                      0.608666  \n",
       "9                      0.617653  \n",
       "10                     0.616868  \n",
       "11                     0.613506  \n",
       "12                     0.618782  \n",
       "13                     0.615999  \n",
       "14                     0.613096  \n",
       "15                     0.609354  \n",
       "16                     0.614012  \n",
       "17                     0.615486  \n",
       "18                     0.607384  \n",
       "19                     0.619296  \n",
       "20                     0.620584  \n",
       "21                     0.616376  \n",
       "22                     0.620481  \n",
       "23                     0.619397  \n",
       "24                     0.611576  \n",
       "25                     0.619854  \n",
       "26                     0.623876  \n",
       "27                     0.620962  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_pth =\"C:\\\\Users\\\\A200274027\\\\vscode\\\\pix\\\\home\\\\playground\\\\ssl_sample\\\\outputs\\\\wanb_export\\\\denoised_sample\\\\exp20_50_recall.csv\"\n",
    "df_recall = pd.read_csv(recall_pth,delimiter=\",\")\n",
    "df_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp2_0 - train/precision</th>\n",
       "      <th>exp2_0 - train/recall</th>\n",
       "      <th>exp2_10 - train/precision</th>\n",
       "      <th>exp2_10 - train/recall</th>\n",
       "      <th>exp2_20 - train/precision</th>\n",
       "      <th>exp2_20 - train/recall</th>\n",
       "      <th>exp2_30 - train/precision</th>\n",
       "      <th>exp2_30 - train/recall</th>\n",
       "      <th>exp2_40 - train/precision</th>\n",
       "      <th>exp2_40 - train/recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531778</td>\n",
       "      <td>0.566709</td>\n",
       "      <td>0.484017</td>\n",
       "      <td>0.575977</td>\n",
       "      <td>0.503271</td>\n",
       "      <td>0.383050</td>\n",
       "      <td>0.530393</td>\n",
       "      <td>0.579739</td>\n",
       "      <td>0.552404</td>\n",
       "      <td>0.527669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.534056</td>\n",
       "      <td>0.575138</td>\n",
       "      <td>0.485145</td>\n",
       "      <td>0.572648</td>\n",
       "      <td>0.505509</td>\n",
       "      <td>0.391654</td>\n",
       "      <td>0.530834</td>\n",
       "      <td>0.575744</td>\n",
       "      <td>0.549489</td>\n",
       "      <td>0.524119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.535476</td>\n",
       "      <td>0.569903</td>\n",
       "      <td>0.485795</td>\n",
       "      <td>0.578525</td>\n",
       "      <td>0.504716</td>\n",
       "      <td>0.386235</td>\n",
       "      <td>0.530662</td>\n",
       "      <td>0.574818</td>\n",
       "      <td>0.555124</td>\n",
       "      <td>0.528498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.540597</td>\n",
       "      <td>0.578698</td>\n",
       "      <td>0.489285</td>\n",
       "      <td>0.587825</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>0.392926</td>\n",
       "      <td>0.535025</td>\n",
       "      <td>0.584177</td>\n",
       "      <td>0.557660</td>\n",
       "      <td>0.531800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.541601</td>\n",
       "      <td>0.583874</td>\n",
       "      <td>0.491367</td>\n",
       "      <td>0.578956</td>\n",
       "      <td>0.518286</td>\n",
       "      <td>0.398805</td>\n",
       "      <td>0.534046</td>\n",
       "      <td>0.582895</td>\n",
       "      <td>0.547308</td>\n",
       "      <td>0.525105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590760</td>\n",
       "      <td>0.688984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590472</td>\n",
       "      <td>0.686073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590680</td>\n",
       "      <td>0.687471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592872</td>\n",
       "      <td>0.689003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590533</td>\n",
       "      <td>0.686839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    exp2_0 - train/precision  exp2_0 - train/recall  \\\n",
       "0                   0.531778               0.566709   \n",
       "1                   0.534056               0.575138   \n",
       "2                   0.535476               0.569903   \n",
       "3                   0.540597               0.578698   \n",
       "4                   0.541601               0.583874   \n",
       "..                       ...                    ...   \n",
       "93                       NaN                    NaN   \n",
       "94                       NaN                    NaN   \n",
       "95                       NaN                    NaN   \n",
       "96                       NaN                    NaN   \n",
       "97                       NaN                    NaN   \n",
       "\n",
       "    exp2_10 - train/precision  exp2_10 - train/recall  \\\n",
       "0                    0.484017                0.575977   \n",
       "1                    0.485145                0.572648   \n",
       "2                    0.485795                0.578525   \n",
       "3                    0.489285                0.587825   \n",
       "4                    0.491367                0.578956   \n",
       "..                        ...                     ...   \n",
       "93                   0.590760                0.688984   \n",
       "94                   0.590472                0.686073   \n",
       "95                   0.590680                0.687471   \n",
       "96                   0.592872                0.689003   \n",
       "97                   0.590533                0.686839   \n",
       "\n",
       "    exp2_20 - train/precision  exp2_20 - train/recall  \\\n",
       "0                    0.503271                0.383050   \n",
       "1                    0.505509                0.391654   \n",
       "2                    0.504716                0.386235   \n",
       "3                    0.507957                0.392926   \n",
       "4                    0.518286                0.398805   \n",
       "..                        ...                     ...   \n",
       "93                        NaN                     NaN   \n",
       "94                        NaN                     NaN   \n",
       "95                        NaN                     NaN   \n",
       "96                        NaN                     NaN   \n",
       "97                        NaN                     NaN   \n",
       "\n",
       "    exp2_30 - train/precision  exp2_30 - train/recall  \\\n",
       "0                    0.530393                0.579739   \n",
       "1                    0.530834                0.575744   \n",
       "2                    0.530662                0.574818   \n",
       "3                    0.535025                0.584177   \n",
       "4                    0.534046                0.582895   \n",
       "..                        ...                     ...   \n",
       "93                        NaN                     NaN   \n",
       "94                        NaN                     NaN   \n",
       "95                        NaN                     NaN   \n",
       "96                        NaN                     NaN   \n",
       "97                        NaN                     NaN   \n",
       "\n",
       "    exp2_40 - train/precision  exp2_40 - train/recall  \n",
       "0                    0.552404                0.527669  \n",
       "1                    0.549489                0.524119  \n",
       "2                    0.555124                0.528498  \n",
       "3                    0.557660                0.531800  \n",
       "4                    0.547308                0.525105  \n",
       "..                        ...                     ...  \n",
       "93                        NaN                     NaN  \n",
       "94                        NaN                     NaN  \n",
       "95                        NaN                     NaN  \n",
       "96                        NaN                     NaN  \n",
       "97                        NaN                     NaN  \n",
       "\n",
       "[98 rows x 10 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_pth = \"C:\\\\Users\\\\A200274027\\\\vscode\\\\pix\\\\home\\\\playground\\\\ssl_sample\\\\outputs\\\\wanb_export\\\\roc\\\\sample_recall_precisions.csv\"\n",
    "df_merged_loaded=pd.read_csv(merged_pth)\n",
    "df_merged_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.516613\n",
       "1     0.519200\n",
       "2     0.517485\n",
       "3     0.518100\n",
       "4     0.522679\n",
       "5     0.522459\n",
       "6     0.519566\n",
       "7     0.520002\n",
       "8     0.519161\n",
       "9     0.524110\n",
       "10    0.522728\n",
       "11    0.520757\n",
       "12    0.520694\n",
       "13    0.521628\n",
       "14    0.521609\n",
       "15    0.521551\n",
       "16    0.520563\n",
       "17    0.523598\n",
       "18    0.519241\n",
       "19    0.525595\n",
       "20    0.523484\n",
       "21    0.519299\n",
       "22    0.523295\n",
       "23    0.524829\n",
       "24    0.523355\n",
       "25    0.526088\n",
       "26    0.528503\n",
       "27    0.524531\n",
       "Name: exp2_50 - train/precision, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_col =df_precision.columns[1]\n",
    "df_precision_data = df_precision[precision_col]\n",
    "df_precision_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.609100\n",
       "1     0.611810\n",
       "2     0.606344\n",
       "3     0.605739\n",
       "4     0.616122\n",
       "5     0.615171\n",
       "6     0.611106\n",
       "7     0.609487\n",
       "8     0.608666\n",
       "9     0.617653\n",
       "10    0.616868\n",
       "11    0.613506\n",
       "12    0.618782\n",
       "13    0.615999\n",
       "14    0.613096\n",
       "15    0.609354\n",
       "16    0.614012\n",
       "17    0.615486\n",
       "18    0.607384\n",
       "19    0.619296\n",
       "20    0.620584\n",
       "21    0.616376\n",
       "22    0.620481\n",
       "23    0.619397\n",
       "24    0.611576\n",
       "25    0.619854\n",
       "26    0.623876\n",
       "27    0.620962\n",
       "Name: exp2_50 - train/recall, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_col =df_recall.columns[1]\n",
    "df_recall_data = df_recall[recall_col]\n",
    "df_recall_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp2_50 - train/precision</th>\n",
       "      <th>exp2_50 - train/recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.516613</td>\n",
       "      <td>0.609100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.519200</td>\n",
       "      <td>0.611810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517485</td>\n",
       "      <td>0.606344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.605739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.522679</td>\n",
       "      <td>0.616122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.522459</td>\n",
       "      <td>0.615171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.519566</td>\n",
       "      <td>0.611106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.520002</td>\n",
       "      <td>0.609487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.519161</td>\n",
       "      <td>0.608666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.524110</td>\n",
       "      <td>0.617653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.522728</td>\n",
       "      <td>0.616868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.520757</td>\n",
       "      <td>0.613506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.520694</td>\n",
       "      <td>0.618782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.521628</td>\n",
       "      <td>0.615999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.521609</td>\n",
       "      <td>0.613096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.521551</td>\n",
       "      <td>0.609354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.520563</td>\n",
       "      <td>0.614012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.523598</td>\n",
       "      <td>0.615486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.519241</td>\n",
       "      <td>0.607384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.525595</td>\n",
       "      <td>0.619296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.523484</td>\n",
       "      <td>0.620584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.519299</td>\n",
       "      <td>0.616376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.523295</td>\n",
       "      <td>0.620481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.524829</td>\n",
       "      <td>0.619397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.523355</td>\n",
       "      <td>0.611576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.526088</td>\n",
       "      <td>0.619854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.528503</td>\n",
       "      <td>0.623876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.524531</td>\n",
       "      <td>0.620962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    exp2_50 - train/precision  exp2_50 - train/recall\n",
       "0                    0.516613                0.609100\n",
       "1                    0.519200                0.611810\n",
       "2                    0.517485                0.606344\n",
       "3                    0.518100                0.605739\n",
       "4                    0.522679                0.616122\n",
       "5                    0.522459                0.615171\n",
       "6                    0.519566                0.611106\n",
       "7                    0.520002                0.609487\n",
       "8                    0.519161                0.608666\n",
       "9                    0.524110                0.617653\n",
       "10                   0.522728                0.616868\n",
       "11                   0.520757                0.613506\n",
       "12                   0.520694                0.618782\n",
       "13                   0.521628                0.615999\n",
       "14                   0.521609                0.613096\n",
       "15                   0.521551                0.609354\n",
       "16                   0.520563                0.614012\n",
       "17                   0.523598                0.615486\n",
       "18                   0.519241                0.607384\n",
       "19                   0.525595                0.619296\n",
       "20                   0.523484                0.620584\n",
       "21                   0.519299                0.616376\n",
       "22                   0.523295                0.620481\n",
       "23                   0.524829                0.619397\n",
       "24                   0.523355                0.611576\n",
       "25                   0.526088                0.619854\n",
       "26                   0.528503                0.623876\n",
       "27                   0.524531                0.620962"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.concat([df_precision_data, df_recall_data], axis=1) \n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp2_0 - train/precision</th>\n",
       "      <th>exp2_0 - train/recall</th>\n",
       "      <th>exp2_10 - train/precision</th>\n",
       "      <th>exp2_10 - train/recall</th>\n",
       "      <th>exp2_20 - train/precision</th>\n",
       "      <th>exp2_20 - train/recall</th>\n",
       "      <th>exp2_30 - train/precision</th>\n",
       "      <th>exp2_30 - train/recall</th>\n",
       "      <th>exp2_40 - train/precision</th>\n",
       "      <th>exp2_40 - train/recall</th>\n",
       "      <th>exp2_50 - train/precision</th>\n",
       "      <th>exp2_50 - train/recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531778</td>\n",
       "      <td>0.566709</td>\n",
       "      <td>0.484017</td>\n",
       "      <td>0.575977</td>\n",
       "      <td>0.503271</td>\n",
       "      <td>0.383050</td>\n",
       "      <td>0.530393</td>\n",
       "      <td>0.579739</td>\n",
       "      <td>0.552404</td>\n",
       "      <td>0.527669</td>\n",
       "      <td>0.516613</td>\n",
       "      <td>0.609100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.534056</td>\n",
       "      <td>0.575138</td>\n",
       "      <td>0.485145</td>\n",
       "      <td>0.572648</td>\n",
       "      <td>0.505509</td>\n",
       "      <td>0.391654</td>\n",
       "      <td>0.530834</td>\n",
       "      <td>0.575744</td>\n",
       "      <td>0.549489</td>\n",
       "      <td>0.524119</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>0.611810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.535476</td>\n",
       "      <td>0.569903</td>\n",
       "      <td>0.485795</td>\n",
       "      <td>0.578525</td>\n",
       "      <td>0.504716</td>\n",
       "      <td>0.386235</td>\n",
       "      <td>0.530662</td>\n",
       "      <td>0.574818</td>\n",
       "      <td>0.555124</td>\n",
       "      <td>0.528498</td>\n",
       "      <td>0.517485</td>\n",
       "      <td>0.606344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.540597</td>\n",
       "      <td>0.578698</td>\n",
       "      <td>0.489285</td>\n",
       "      <td>0.587825</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>0.392926</td>\n",
       "      <td>0.535025</td>\n",
       "      <td>0.584177</td>\n",
       "      <td>0.557660</td>\n",
       "      <td>0.531800</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.605739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.541601</td>\n",
       "      <td>0.583874</td>\n",
       "      <td>0.491367</td>\n",
       "      <td>0.578956</td>\n",
       "      <td>0.518286</td>\n",
       "      <td>0.398805</td>\n",
       "      <td>0.534046</td>\n",
       "      <td>0.582895</td>\n",
       "      <td>0.547308</td>\n",
       "      <td>0.525105</td>\n",
       "      <td>0.522679</td>\n",
       "      <td>0.616122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590760</td>\n",
       "      <td>0.688984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590472</td>\n",
       "      <td>0.686073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590680</td>\n",
       "      <td>0.687471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592872</td>\n",
       "      <td>0.689003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590533</td>\n",
       "      <td>0.686839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    exp2_0 - train/precision  exp2_0 - train/recall  \\\n",
       "0                   0.531778               0.566709   \n",
       "1                   0.534056               0.575138   \n",
       "2                   0.535476               0.569903   \n",
       "3                   0.540597               0.578698   \n",
       "4                   0.541601               0.583874   \n",
       "..                       ...                    ...   \n",
       "93                       NaN                    NaN   \n",
       "94                       NaN                    NaN   \n",
       "95                       NaN                    NaN   \n",
       "96                       NaN                    NaN   \n",
       "97                       NaN                    NaN   \n",
       "\n",
       "    exp2_10 - train/precision  exp2_10 - train/recall  \\\n",
       "0                    0.484017                0.575977   \n",
       "1                    0.485145                0.572648   \n",
       "2                    0.485795                0.578525   \n",
       "3                    0.489285                0.587825   \n",
       "4                    0.491367                0.578956   \n",
       "..                        ...                     ...   \n",
       "93                   0.590760                0.688984   \n",
       "94                   0.590472                0.686073   \n",
       "95                   0.590680                0.687471   \n",
       "96                   0.592872                0.689003   \n",
       "97                   0.590533                0.686839   \n",
       "\n",
       "    exp2_20 - train/precision  exp2_20 - train/recall  \\\n",
       "0                    0.503271                0.383050   \n",
       "1                    0.505509                0.391654   \n",
       "2                    0.504716                0.386235   \n",
       "3                    0.507957                0.392926   \n",
       "4                    0.518286                0.398805   \n",
       "..                        ...                     ...   \n",
       "93                        NaN                     NaN   \n",
       "94                        NaN                     NaN   \n",
       "95                        NaN                     NaN   \n",
       "96                        NaN                     NaN   \n",
       "97                        NaN                     NaN   \n",
       "\n",
       "    exp2_30 - train/precision  exp2_30 - train/recall  \\\n",
       "0                    0.530393                0.579739   \n",
       "1                    0.530834                0.575744   \n",
       "2                    0.530662                0.574818   \n",
       "3                    0.535025                0.584177   \n",
       "4                    0.534046                0.582895   \n",
       "..                        ...                     ...   \n",
       "93                        NaN                     NaN   \n",
       "94                        NaN                     NaN   \n",
       "95                        NaN                     NaN   \n",
       "96                        NaN                     NaN   \n",
       "97                        NaN                     NaN   \n",
       "\n",
       "    exp2_40 - train/precision  exp2_40 - train/recall  \\\n",
       "0                    0.552404                0.527669   \n",
       "1                    0.549489                0.524119   \n",
       "2                    0.555124                0.528498   \n",
       "3                    0.557660                0.531800   \n",
       "4                    0.547308                0.525105   \n",
       "..                        ...                     ...   \n",
       "93                        NaN                     NaN   \n",
       "94                        NaN                     NaN   \n",
       "95                        NaN                     NaN   \n",
       "96                        NaN                     NaN   \n",
       "97                        NaN                     NaN   \n",
       "\n",
       "    exp2_50 - train/precision  exp2_50 - train/recall  \n",
       "0                    0.516613                0.609100  \n",
       "1                    0.519200                0.611810  \n",
       "2                    0.517485                0.606344  \n",
       "3                    0.518100                0.605739  \n",
       "4                    0.522679                0.616122  \n",
       "..                        ...                     ...  \n",
       "93                        NaN                     NaN  \n",
       "94                        NaN                     NaN  \n",
       "95                        NaN                     NaN  \n",
       "96                        NaN                     NaN  \n",
       "97                        NaN                     NaN  \n",
       "\n",
       "[98 rows x 12 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.concat([df_merged_loaded, df_merged], axis=1) \n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pth = \"C:\\\\Users\\\\A200274027\\\\vscode\\\\pix\\\\home\\\\playground\\\\ssl_sample\\\\outputs\\\\wanb_export\\\\roc\\\\sample_recall_precisions.csv\"\n",
    "df_merged.to_csv(merged_pth,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp2_0 - train/precision</th>\n",
       "      <th>exp2_0 - train/recall</th>\n",
       "      <th>exp2_10 - train/precision</th>\n",
       "      <th>exp2_10 - train/recall</th>\n",
       "      <th>exp2_20 - train/precision</th>\n",
       "      <th>exp2_20 - train/recall</th>\n",
       "      <th>exp2_30 - train/precision</th>\n",
       "      <th>exp2_30 - train/recall</th>\n",
       "      <th>exp2_40 - train/precision</th>\n",
       "      <th>exp2_40 - train/recall</th>\n",
       "      <th>exp2_50 - train/precision</th>\n",
       "      <th>exp2_50 - train/recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531778</td>\n",
       "      <td>0.566709</td>\n",
       "      <td>0.484017</td>\n",
       "      <td>0.575977</td>\n",
       "      <td>0.503271</td>\n",
       "      <td>0.383050</td>\n",
       "      <td>0.530393</td>\n",
       "      <td>0.579739</td>\n",
       "      <td>0.552404</td>\n",
       "      <td>0.527669</td>\n",
       "      <td>0.516613</td>\n",
       "      <td>0.609100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.534056</td>\n",
       "      <td>0.575138</td>\n",
       "      <td>0.485145</td>\n",
       "      <td>0.572648</td>\n",
       "      <td>0.505509</td>\n",
       "      <td>0.391654</td>\n",
       "      <td>0.530834</td>\n",
       "      <td>0.575744</td>\n",
       "      <td>0.549489</td>\n",
       "      <td>0.524119</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>0.611810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.535476</td>\n",
       "      <td>0.569903</td>\n",
       "      <td>0.485795</td>\n",
       "      <td>0.578525</td>\n",
       "      <td>0.504716</td>\n",
       "      <td>0.386235</td>\n",
       "      <td>0.530662</td>\n",
       "      <td>0.574818</td>\n",
       "      <td>0.555124</td>\n",
       "      <td>0.528498</td>\n",
       "      <td>0.517485</td>\n",
       "      <td>0.606344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.540597</td>\n",
       "      <td>0.578698</td>\n",
       "      <td>0.489285</td>\n",
       "      <td>0.587825</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>0.392926</td>\n",
       "      <td>0.535025</td>\n",
       "      <td>0.584177</td>\n",
       "      <td>0.557660</td>\n",
       "      <td>0.531800</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.605739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.541601</td>\n",
       "      <td>0.583874</td>\n",
       "      <td>0.491367</td>\n",
       "      <td>0.578956</td>\n",
       "      <td>0.518286</td>\n",
       "      <td>0.398805</td>\n",
       "      <td>0.534046</td>\n",
       "      <td>0.582895</td>\n",
       "      <td>0.547308</td>\n",
       "      <td>0.525105</td>\n",
       "      <td>0.522679</td>\n",
       "      <td>0.616122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590760</td>\n",
       "      <td>0.688984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590472</td>\n",
       "      <td>0.686073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590680</td>\n",
       "      <td>0.687471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592872</td>\n",
       "      <td>0.689003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590533</td>\n",
       "      <td>0.686839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    exp2_0 - train/precision  exp2_0 - train/recall  \\\n",
       "0                   0.531778               0.566709   \n",
       "1                   0.534056               0.575138   \n",
       "2                   0.535476               0.569903   \n",
       "3                   0.540597               0.578698   \n",
       "4                   0.541601               0.583874   \n",
       "..                       ...                    ...   \n",
       "93                       NaN                    NaN   \n",
       "94                       NaN                    NaN   \n",
       "95                       NaN                    NaN   \n",
       "96                       NaN                    NaN   \n",
       "97                       NaN                    NaN   \n",
       "\n",
       "    exp2_10 - train/precision  exp2_10 - train/recall  \\\n",
       "0                    0.484017                0.575977   \n",
       "1                    0.485145                0.572648   \n",
       "2                    0.485795                0.578525   \n",
       "3                    0.489285                0.587825   \n",
       "4                    0.491367                0.578956   \n",
       "..                        ...                     ...   \n",
       "93                   0.590760                0.688984   \n",
       "94                   0.590472                0.686073   \n",
       "95                   0.590680                0.687471   \n",
       "96                   0.592872                0.689003   \n",
       "97                   0.590533                0.686839   \n",
       "\n",
       "    exp2_20 - train/precision  exp2_20 - train/recall  \\\n",
       "0                    0.503271                0.383050   \n",
       "1                    0.505509                0.391654   \n",
       "2                    0.504716                0.386235   \n",
       "3                    0.507957                0.392926   \n",
       "4                    0.518286                0.398805   \n",
       "..                        ...                     ...   \n",
       "93                        NaN                     NaN   \n",
       "94                        NaN                     NaN   \n",
       "95                        NaN                     NaN   \n",
       "96                        NaN                     NaN   \n",
       "97                        NaN                     NaN   \n",
       "\n",
       "    exp2_30 - train/precision  exp2_30 - train/recall  \\\n",
       "0                    0.530393                0.579739   \n",
       "1                    0.530834                0.575744   \n",
       "2                    0.530662                0.574818   \n",
       "3                    0.535025                0.584177   \n",
       "4                    0.534046                0.582895   \n",
       "..                        ...                     ...   \n",
       "93                        NaN                     NaN   \n",
       "94                        NaN                     NaN   \n",
       "95                        NaN                     NaN   \n",
       "96                        NaN                     NaN   \n",
       "97                        NaN                     NaN   \n",
       "\n",
       "    exp2_40 - train/precision  exp2_40 - train/recall  \\\n",
       "0                    0.552404                0.527669   \n",
       "1                    0.549489                0.524119   \n",
       "2                    0.555124                0.528498   \n",
       "3                    0.557660                0.531800   \n",
       "4                    0.547308                0.525105   \n",
       "..                        ...                     ...   \n",
       "93                        NaN                     NaN   \n",
       "94                        NaN                     NaN   \n",
       "95                        NaN                     NaN   \n",
       "96                        NaN                     NaN   \n",
       "97                        NaN                     NaN   \n",
       "\n",
       "    exp2_50 - train/precision  exp2_50 - train/recall  \n",
       "0                    0.516613                0.609100  \n",
       "1                    0.519200                0.611810  \n",
       "2                    0.517485                0.606344  \n",
       "3                    0.518100                0.605739  \n",
       "4                    0.522679                0.616122  \n",
       "..                        ...                     ...  \n",
       "93                        NaN                     NaN  \n",
       "94                        NaN                     NaN  \n",
       "95                        NaN                     NaN  \n",
       "96                        NaN                     NaN  \n",
       "97                        NaN                     NaN  \n",
       "\n",
       "[98 rows x 12 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp2_0 - train/precision</th>\n",
       "      <th>exp2_0 - train/recall</th>\n",
       "      <th>exp2_10 - train/precision</th>\n",
       "      <th>exp2_10 - train/recall</th>\n",
       "      <th>exp2_20 - train/precision</th>\n",
       "      <th>exp2_20 - train/recall</th>\n",
       "      <th>exp2_30 - train/precision</th>\n",
       "      <th>exp2_30 - train/recall</th>\n",
       "      <th>exp2_40 - train/precision</th>\n",
       "      <th>exp2_40 - train/recall</th>\n",
       "      <th>exp2_50 - train/precision</th>\n",
       "      <th>exp2_50 - train/recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531778</td>\n",
       "      <td>0.566709</td>\n",
       "      <td>0.484017</td>\n",
       "      <td>0.575977</td>\n",
       "      <td>0.503271</td>\n",
       "      <td>0.383050</td>\n",
       "      <td>0.530393</td>\n",
       "      <td>0.579739</td>\n",
       "      <td>0.552404</td>\n",
       "      <td>0.527669</td>\n",
       "      <td>0.516613</td>\n",
       "      <td>0.609100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.534056</td>\n",
       "      <td>0.575138</td>\n",
       "      <td>0.485145</td>\n",
       "      <td>0.572648</td>\n",
       "      <td>0.505509</td>\n",
       "      <td>0.391654</td>\n",
       "      <td>0.530834</td>\n",
       "      <td>0.575744</td>\n",
       "      <td>0.549489</td>\n",
       "      <td>0.524119</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>0.611810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.535476</td>\n",
       "      <td>0.569903</td>\n",
       "      <td>0.485795</td>\n",
       "      <td>0.578525</td>\n",
       "      <td>0.504716</td>\n",
       "      <td>0.386235</td>\n",
       "      <td>0.530662</td>\n",
       "      <td>0.574818</td>\n",
       "      <td>0.555124</td>\n",
       "      <td>0.528498</td>\n",
       "      <td>0.517485</td>\n",
       "      <td>0.606344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.540597</td>\n",
       "      <td>0.578698</td>\n",
       "      <td>0.489285</td>\n",
       "      <td>0.587825</td>\n",
       "      <td>0.507957</td>\n",
       "      <td>0.392926</td>\n",
       "      <td>0.535025</td>\n",
       "      <td>0.584177</td>\n",
       "      <td>0.557660</td>\n",
       "      <td>0.531800</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.605739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.541601</td>\n",
       "      <td>0.583874</td>\n",
       "      <td>0.491367</td>\n",
       "      <td>0.578956</td>\n",
       "      <td>0.518286</td>\n",
       "      <td>0.398805</td>\n",
       "      <td>0.534046</td>\n",
       "      <td>0.582895</td>\n",
       "      <td>0.547308</td>\n",
       "      <td>0.525105</td>\n",
       "      <td>0.522679</td>\n",
       "      <td>0.616122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590760</td>\n",
       "      <td>0.688984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590472</td>\n",
       "      <td>0.686073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590680</td>\n",
       "      <td>0.687471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592872</td>\n",
       "      <td>0.689003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.590533</td>\n",
       "      <td>0.686839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    exp2_0 - train/precision  exp2_0 - train/recall  \\\n",
       "0                   0.531778               0.566709   \n",
       "1                   0.534056               0.575138   \n",
       "2                   0.535476               0.569903   \n",
       "3                   0.540597               0.578698   \n",
       "4                   0.541601               0.583874   \n",
       "..                       ...                    ...   \n",
       "93                       NaN                    NaN   \n",
       "94                       NaN                    NaN   \n",
       "95                       NaN                    NaN   \n",
       "96                       NaN                    NaN   \n",
       "97                       NaN                    NaN   \n",
       "\n",
       "    exp2_10 - train/precision  exp2_10 - train/recall  \\\n",
       "0                    0.484017                0.575977   \n",
       "1                    0.485145                0.572648   \n",
       "2                    0.485795                0.578525   \n",
       "3                    0.489285                0.587825   \n",
       "4                    0.491367                0.578956   \n",
       "..                        ...                     ...   \n",
       "93                   0.590760                0.688984   \n",
       "94                   0.590472                0.686073   \n",
       "95                   0.590680                0.687471   \n",
       "96                   0.592872                0.689003   \n",
       "97                   0.590533                0.686839   \n",
       "\n",
       "    exp2_20 - train/precision  exp2_20 - train/recall  \\\n",
       "0                    0.503271                0.383050   \n",
       "1                    0.505509                0.391654   \n",
       "2                    0.504716                0.386235   \n",
       "3                    0.507957                0.392926   \n",
       "4                    0.518286                0.398805   \n",
       "..                        ...                     ...   \n",
       "93                        NaN                     NaN   \n",
       "94                        NaN                     NaN   \n",
       "95                        NaN                     NaN   \n",
       "96                        NaN                     NaN   \n",
       "97                        NaN                     NaN   \n",
       "\n",
       "    exp2_30 - train/precision  exp2_30 - train/recall  \\\n",
       "0                    0.530393                0.579739   \n",
       "1                    0.530834                0.575744   \n",
       "2                    0.530662                0.574818   \n",
       "3                    0.535025                0.584177   \n",
       "4                    0.534046                0.582895   \n",
       "..                        ...                     ...   \n",
       "93                        NaN                     NaN   \n",
       "94                        NaN                     NaN   \n",
       "95                        NaN                     NaN   \n",
       "96                        NaN                     NaN   \n",
       "97                        NaN                     NaN   \n",
       "\n",
       "    exp2_40 - train/precision  exp2_40 - train/recall  \\\n",
       "0                    0.552404                0.527669   \n",
       "1                    0.549489                0.524119   \n",
       "2                    0.555124                0.528498   \n",
       "3                    0.557660                0.531800   \n",
       "4                    0.547308                0.525105   \n",
       "..                        ...                     ...   \n",
       "93                        NaN                     NaN   \n",
       "94                        NaN                     NaN   \n",
       "95                        NaN                     NaN   \n",
       "96                        NaN                     NaN   \n",
       "97                        NaN                     NaN   \n",
       "\n",
       "    exp2_50 - train/precision  exp2_50 - train/recall  \n",
       "0                    0.516613                0.609100  \n",
       "1                    0.519200                0.611810  \n",
       "2                    0.517485                0.606344  \n",
       "3                    0.518100                0.605739  \n",
       "4                    0.522679                0.616122  \n",
       "..                        ...                     ...  \n",
       "93                        NaN                     NaN  \n",
       "94                        NaN                     NaN  \n",
       "95                        NaN                     NaN  \n",
       "96                        NaN                     NaN  \n",
       "97                        NaN                     NaN  \n",
       "\n",
       "[98 rows x 12 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve  \n",
    "import matplotlib.pyplot as plt  \n",
    "df_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_prec=[]\n",
    "outputs_recall =[]\n",
    "ids =[\"0%\",\"10%\",\"20%\",\"30%\",\"40%\",\"50%\"]\n",
    "plt.xlabel(\"flip percentage\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.title(\"F1 Score\")\n",
    "for i in range(0,df_merged.shape[1],2):\n",
    "    prec= df_merged.iloc[:,i].dropna()\n",
    "    recall = df_merged.iloc[:,i+1].dropna()\n",
    "\n",
    "    outputs_prec.append(prec)\n",
    "    outputs_recall.append(recall)\n",
    "#for i in range(1):\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DownstreamClassifier(\n",
       "  (pretrained): SSLModel(\n",
       "    (masker): Masker()\n",
       "    (pos_emb): PositionEmbedding(\n",
       "      (pos_emb): Embedding(21, 200)\n",
       "    )\n",
       "    (encoder): ModuleList(\n",
       "      (0-4): 5 x TransformerBlock(\n",
       "        (multihead_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=201, out_features=201, bias=True)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedForward(\n",
       "          (linear_in): Linear(in_features=201, out_features=128, bias=True)\n",
       "          (linear_out): Linear(in_features=128, out_features=201, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layernorm_attention): LayerNorm((201,), eps=1e-05, elementwise_affine=True)\n",
       "        (layernorm_feedforward): LayerNorm((201,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): ModuleList(\n",
       "      (0-2): 3 x TransformerBlock(\n",
       "        (multihead_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=201, out_features=201, bias=True)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedForward(\n",
       "          (linear_in): Linear(in_features=201, out_features=128, bias=True)\n",
       "          (linear_out): Linear(in_features=128, out_features=201, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layernorm_attention): LayerNorm((201,), eps=1e-05, elementwise_affine=True)\n",
       "        (layernorm_feedforward): LayerNorm((201,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (proj_head_reg): Linear(in_features=201, out_features=1, bias=True)\n",
       "  )\n",
       "  (projection_layer): Linear(in_features=21, out_features=1, bias=True)\n",
       "  (criterion): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import ssl,logistic_regression\n",
    "pth = \"C:\\\\Users\\\\A200274027\\\\vscode\\\\pix\\\\home\\\\playground\\\\ssl_sample\\\\outputs\\\\sftlocal\\\\denoised\\\\exp_4\\\\noise_30.ckpt\"\n",
    "model=logistic_regression.DownstreamClassifier.load_from_checkpoint(pth)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DownstreamClassifier(\n",
       "  (pretrained): SSLModel(\n",
       "    (masker): Masker()\n",
       "    (pos_emb): PositionEmbedding(\n",
       "      (pos_emb): Embedding(21, 200)\n",
       "    )\n",
       "    (encoder): ModuleList(\n",
       "      (0-4): 5 x TransformerBlock(\n",
       "        (multihead_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=201, out_features=201, bias=True)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedForward(\n",
       "          (linear_in): Linear(in_features=201, out_features=128, bias=True)\n",
       "          (linear_out): Linear(in_features=128, out_features=201, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layernorm_attention): LayerNorm((201,), eps=1e-05, elementwise_affine=True)\n",
       "        (layernorm_feedforward): LayerNorm((201,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): ModuleList(\n",
       "      (0-2): 3 x TransformerBlock(\n",
       "        (multihead_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=201, out_features=201, bias=True)\n",
       "        )\n",
       "        (feedforward): PositionwiseFeedForward(\n",
       "          (linear_in): Linear(in_features=201, out_features=128, bias=True)\n",
       "          (linear_out): Linear(in_features=128, out_features=201, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layernorm_attention): LayerNorm((201,), eps=1e-05, elementwise_affine=True)\n",
       "        (layernorm_feedforward): LayerNorm((201,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (proj_head_reg): Linear(in_features=201, out_features=1, bias=True)\n",
       "  )\n",
       "  (projection_layer): Linear(in_features=21, out_features=1, bias=True)\n",
       "  (criterion): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_13</th>\n",
       "      <th>f_14</th>\n",
       "      <th>f_15</th>\n",
       "      <th>f_16</th>\n",
       "      <th>f_17</th>\n",
       "      <th>f_18</th>\n",
       "      <th>f_19</th>\n",
       "      <th>f_20</th>\n",
       "      <th>label</th>\n",
       "      <th>label_flip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.312019</td>\n",
       "      <td>1.528114</td>\n",
       "      <td>-0.648514</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>-1.373440</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>0.622271</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>1.558192</td>\n",
       "      <td>...</td>\n",
       "      <td>1.187948</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>-1.229745</td>\n",
       "      <td>-0.042057</td>\n",
       "      <td>-0.777582</td>\n",
       "      <td>-0.052806</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.309700</td>\n",
       "      <td>-2.702552</td>\n",
       "      <td>0.533542</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>0.622271</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>-0.789617</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.045919</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-0.517723</td>\n",
       "      <td>-0.283761</td>\n",
       "      <td>0.034922</td>\n",
       "      <td>1.101138</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.309700</td>\n",
       "      <td>-0.164153</td>\n",
       "      <td>0.240776</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>1.595420</td>\n",
       "      <td>...</td>\n",
       "      <td>1.187948</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-0.927380</td>\n",
       "      <td>1.601528</td>\n",
       "      <td>-0.748930</td>\n",
       "      <td>1.386680</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.498841</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>-0.590548</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>-0.189015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071015</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-1.005409</td>\n",
       "      <td>-0.456406</td>\n",
       "      <td>-0.742790</td>\n",
       "      <td>-0.326573</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.498841</td>\n",
       "      <td>-0.587219</td>\n",
       "      <td>-0.481692</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-3.502058</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>-1.335883</td>\n",
       "      <td>-0.789617</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.045919</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>1.676865</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>-0.491057</td>\n",
       "      <td>-0.812289</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31007</th>\n",
       "      <td>-1.122878</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>0.076099</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>-1.373440</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>0.622271</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>0.046759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071015</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>-1.200484</td>\n",
       "      <td>0.310140</td>\n",
       "      <td>0.413546</td>\n",
       "      <td>0.176805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31008</th>\n",
       "      <td>-1.122878</td>\n",
       "      <td>-0.587219</td>\n",
       "      <td>-1.174059</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>-1.373440</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>-1.335883</td>\n",
       "      <td>-0.789617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071015</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-1.190730</td>\n",
       "      <td>0.289422</td>\n",
       "      <td>-0.179972</td>\n",
       "      <td>-1.089000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31009</th>\n",
       "      <td>-1.122878</td>\n",
       "      <td>-0.446197</td>\n",
       "      <td>-0.486981</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>2.561865</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>-1.335883</td>\n",
       "      <td>-0.789617</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.045919</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>-1.661825</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>-1.395558</td>\n",
       "      <td>-0.608334</td>\n",
       "      <td>-0.249557</td>\n",
       "      <td>-0.620947</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31010</th>\n",
       "      <td>-1.122878</td>\n",
       "      <td>-0.164153</td>\n",
       "      <td>-0.225371</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>0.039313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.187948</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>-1.661825</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>-0.790827</td>\n",
       "      <td>-0.725733</td>\n",
       "      <td>0.145439</td>\n",
       "      <td>-0.317742</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31011</th>\n",
       "      <td>-0.312019</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>0.063108</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>0.622271</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>-1.335883</td>\n",
       "      <td>-0.747426</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.045919</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-0.654275</td>\n",
       "      <td>-0.152550</td>\n",
       "      <td>-0.448078</td>\n",
       "      <td>0.276892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31012 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
       "0     -0.312019  1.528114 -0.648514 -0.186118 -1.373440 -0.390341  0.622271   \n",
       "1      1.309700 -2.702552  0.533542 -0.186118  0.728099 -0.390341  0.622271   \n",
       "2      1.309700 -0.164153  0.240776 -0.186118  0.728099 -0.390341 -1.341695   \n",
       "3      0.498841  0.681981 -0.590548 -0.186118  0.728099 -0.390341 -1.341695   \n",
       "4      0.498841 -0.587219 -0.481692 -0.186118  0.728099 -0.390341 -3.502058   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "31007 -1.122878  0.681981  0.076099 -0.186118 -1.373440 -0.390341  0.622271   \n",
       "31008 -1.122878 -0.587219 -1.174059 -0.186118 -1.373440 -0.390341 -1.341695   \n",
       "31009 -1.122878 -0.446197 -0.486981 -0.186118  0.728099  2.561865 -1.341695   \n",
       "31010 -1.122878 -0.164153 -0.225371 -0.186118  0.728099 -0.390341 -1.341695   \n",
       "31011 -0.312019  0.681981  0.063108 -0.186118  0.728099 -0.390341  0.622271   \n",
       "\n",
       "            f_7       f_8       f_9  ...      f_13      f_14      f_15  \\\n",
       "0     -0.210163  0.748568  1.558192  ...  1.187948 -0.301761  0.601748   \n",
       "1     -0.210163  0.748568 -0.789617  ... -1.045919 -0.301761  0.601748   \n",
       "2     -0.210163  0.748568  1.595420  ...  1.187948 -0.301761  0.601748   \n",
       "3     -0.210163  0.748568 -0.189015  ...  0.071015 -0.301761  0.601748   \n",
       "4     -0.210163 -1.335883 -0.789617  ... -1.045919 -0.301761  0.601748   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "31007 -0.210163  0.748568  0.046759  ...  0.071015 -0.301761  0.601748   \n",
       "31008 -0.210163 -1.335883 -0.789617  ...  0.071015 -0.301761  0.601748   \n",
       "31009 -0.210163 -1.335883 -0.789617  ... -1.045919 -0.301761 -1.661825   \n",
       "31010 -0.210163  0.748568  0.039313  ...  1.187948 -0.301761 -1.661825   \n",
       "31011 -0.210163 -1.335883 -0.747426  ... -1.045919 -0.301761  0.601748   \n",
       "\n",
       "           f_16      f_17      f_18      f_19      f_20  label  label_flip  \n",
       "0     -0.721294 -1.229745 -0.042057 -0.777582 -0.052806      1           1  \n",
       "1      1.386397 -0.517723 -0.283761  0.034922  1.101138      1           1  \n",
       "2      1.386397 -0.927380  1.601528 -0.748930  1.386680      0           0  \n",
       "3      1.386397 -1.005409 -0.456406 -0.742790 -0.326573      0           0  \n",
       "4     -0.721294  1.676865  0.904040 -0.491057 -0.812289      1           1  \n",
       "...         ...       ...       ...       ...       ...    ...         ...  \n",
       "31007 -0.721294 -1.200484  0.310140  0.413546  0.176805      0           0  \n",
       "31008  1.386397 -1.190730  0.289422 -0.179972 -1.089000      0           0  \n",
       "31009 -0.721294 -1.395558 -0.608334 -0.249557 -0.620947      0           0  \n",
       "31010 -0.721294 -0.790827 -0.725733  0.145439 -0.317742      1           1  \n",
       "31011  1.386397 -0.654275 -0.152550 -0.448078  0.276892      0           0  \n",
       "\n",
       "[31012 rows x 23 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_pth = \"C:\\\\Users\\\\A200274027\\\\vscode\\\\pix\\\\home\\\\playground\\\\ssl_sample\\\\data\\\\sample\\\\train\\\\scaled\\\\denoised\\\\train_flipped_labels_10.csv\"\n",
    "#input_pth = \"C:\\\\Users\\\\A200274027\\\\vscode\\\\pix\\\\home\\\\playground\\\\ssl_sample\\\\data\\\\sample\\\\train\\\\scaled\\\\denoised\\\\train_.csv\"\n",
    "input_data = pd.read_csv(input_pth)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_11</th>\n",
       "      <th>f_12</th>\n",
       "      <th>f_13</th>\n",
       "      <th>f_14</th>\n",
       "      <th>f_15</th>\n",
       "      <th>f_16</th>\n",
       "      <th>f_17</th>\n",
       "      <th>f_18</th>\n",
       "      <th>f_19</th>\n",
       "      <th>f_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.312019</td>\n",
       "      <td>1.528114</td>\n",
       "      <td>-0.648514</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>-1.373440</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>0.622271</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>1.558192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>1.187948</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>-1.229745</td>\n",
       "      <td>-0.042057</td>\n",
       "      <td>-0.777582</td>\n",
       "      <td>-0.052806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.309700</td>\n",
       "      <td>-2.702552</td>\n",
       "      <td>0.533542</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>0.622271</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>-0.789617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>-1.163636</td>\n",
       "      <td>-1.045919</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-0.517723</td>\n",
       "      <td>-0.283761</td>\n",
       "      <td>0.034922</td>\n",
       "      <td>1.101138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.309700</td>\n",
       "      <td>-0.164153</td>\n",
       "      <td>0.240776</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>1.595420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>1.187948</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-0.927380</td>\n",
       "      <td>1.601528</td>\n",
       "      <td>-0.748930</td>\n",
       "      <td>1.386680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.498841</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>-0.590548</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>-0.189015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.071015</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-1.005409</td>\n",
       "      <td>-0.456406</td>\n",
       "      <td>-0.742790</td>\n",
       "      <td>-0.326573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.498841</td>\n",
       "      <td>-0.587219</td>\n",
       "      <td>-0.481692</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-3.502058</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>-1.335883</td>\n",
       "      <td>-0.789617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>-1.163636</td>\n",
       "      <td>-1.045919</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>1.676865</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>-0.491057</td>\n",
       "      <td>-0.812289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31007</th>\n",
       "      <td>-1.122878</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>0.076099</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>-1.373440</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>0.622271</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>0.046759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.071015</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>-1.200484</td>\n",
       "      <td>0.310140</td>\n",
       "      <td>0.413546</td>\n",
       "      <td>0.176805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31008</th>\n",
       "      <td>-1.122878</td>\n",
       "      <td>-0.587219</td>\n",
       "      <td>-1.174059</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>-1.373440</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>-1.335883</td>\n",
       "      <td>-0.789617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>-1.163636</td>\n",
       "      <td>0.071015</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-1.190730</td>\n",
       "      <td>0.289422</td>\n",
       "      <td>-0.179972</td>\n",
       "      <td>-1.089000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31009</th>\n",
       "      <td>-1.122878</td>\n",
       "      <td>-0.446197</td>\n",
       "      <td>-0.486981</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>2.561865</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>-1.335883</td>\n",
       "      <td>-0.789617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>-1.163636</td>\n",
       "      <td>-1.045919</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>-1.661825</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>-1.395558</td>\n",
       "      <td>-0.608334</td>\n",
       "      <td>-0.249557</td>\n",
       "      <td>-0.620947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31010</th>\n",
       "      <td>-1.122878</td>\n",
       "      <td>-0.164153</td>\n",
       "      <td>-0.225371</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>0.039313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>1.187948</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>-1.661825</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>-0.790827</td>\n",
       "      <td>-0.725733</td>\n",
       "      <td>0.145439</td>\n",
       "      <td>-0.317742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31011</th>\n",
       "      <td>-0.312019</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>0.063108</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>0.622271</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>-1.335883</td>\n",
       "      <td>-0.747426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>-1.163636</td>\n",
       "      <td>-1.045919</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-0.654275</td>\n",
       "      <td>-0.152550</td>\n",
       "      <td>-0.448078</td>\n",
       "      <td>0.276892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31012 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
       "0     -0.312019  1.528114 -0.648514 -0.186118 -1.373440 -0.390341  0.622271   \n",
       "1      1.309700 -2.702552  0.533542 -0.186118  0.728099 -0.390341  0.622271   \n",
       "2      1.309700 -0.164153  0.240776 -0.186118  0.728099 -0.390341 -1.341695   \n",
       "3      0.498841  0.681981 -0.590548 -0.186118  0.728099 -0.390341 -1.341695   \n",
       "4      0.498841 -0.587219 -0.481692 -0.186118  0.728099 -0.390341 -3.502058   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "31007 -1.122878  0.681981  0.076099 -0.186118 -1.373440 -0.390341  0.622271   \n",
       "31008 -1.122878 -0.587219 -1.174059 -0.186118 -1.373440 -0.390341 -1.341695   \n",
       "31009 -1.122878 -0.446197 -0.486981 -0.186118  0.728099  2.561865 -1.341695   \n",
       "31010 -1.122878 -0.164153 -0.225371 -0.186118  0.728099 -0.390341 -1.341695   \n",
       "31011 -0.312019  0.681981  0.063108 -0.186118  0.728099 -0.390341  0.622271   \n",
       "\n",
       "            f_7       f_8       f_9  ...      f_11      f_12      f_13  \\\n",
       "0     -0.210163  0.748568  1.558192  ...  0.408986  0.859375  1.187948   \n",
       "1     -0.210163  0.748568 -0.789617  ...  0.408986 -1.163636 -1.045919   \n",
       "2     -0.210163  0.748568  1.595420  ...  0.408986  0.859375  1.187948   \n",
       "3     -0.210163  0.748568 -0.189015  ...  0.408986  0.859375  0.071015   \n",
       "4     -0.210163 -1.335883 -0.789617  ...  0.408986 -1.163636 -1.045919   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "31007 -0.210163  0.748568  0.046759  ...  0.408986  0.859375  0.071015   \n",
       "31008 -0.210163 -1.335883 -0.789617  ...  0.408986 -1.163636  0.071015   \n",
       "31009 -0.210163 -1.335883 -0.789617  ...  0.408986 -1.163636 -1.045919   \n",
       "31010 -0.210163  0.748568  0.039313  ...  0.408986  0.859375  1.187948   \n",
       "31011 -0.210163 -1.335883 -0.747426  ...  0.408986 -1.163636 -1.045919   \n",
       "\n",
       "           f_14      f_15      f_16      f_17      f_18      f_19      f_20  \n",
       "0     -0.301761  0.601748 -0.721294 -1.229745 -0.042057 -0.777582 -0.052806  \n",
       "1     -0.301761  0.601748  1.386397 -0.517723 -0.283761  0.034922  1.101138  \n",
       "2     -0.301761  0.601748  1.386397 -0.927380  1.601528 -0.748930  1.386680  \n",
       "3     -0.301761  0.601748  1.386397 -1.005409 -0.456406 -0.742790 -0.326573  \n",
       "4     -0.301761  0.601748 -0.721294  1.676865  0.904040 -0.491057 -0.812289  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "31007 -0.301761  0.601748 -0.721294 -1.200484  0.310140  0.413546  0.176805  \n",
       "31008 -0.301761  0.601748  1.386397 -1.190730  0.289422 -0.179972 -1.089000  \n",
       "31009 -0.301761 -1.661825 -0.721294 -1.395558 -0.608334 -0.249557 -0.620947  \n",
       "31010 -0.301761 -1.661825 -0.721294 -0.790827 -0.725733  0.145439 -0.317742  \n",
       "31011 -0.301761  0.601748  1.386397 -0.654275 -0.152550 -0.448078  0.276892  \n",
       "\n",
       "[31012 rows x 21 columns]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = input_data[\"label_flip\"]\n",
    "inputs = input_data.iloc[:,:-2]\n",
    "inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_11</th>\n",
       "      <th>f_12</th>\n",
       "      <th>f_13</th>\n",
       "      <th>f_14</th>\n",
       "      <th>f_15</th>\n",
       "      <th>f_16</th>\n",
       "      <th>f_17</th>\n",
       "      <th>f_18</th>\n",
       "      <th>f_19</th>\n",
       "      <th>f_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.312019</td>\n",
       "      <td>1.528114</td>\n",
       "      <td>-0.648514</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>-1.373440</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>0.622271</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>1.558192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>1.187948</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>-1.229745</td>\n",
       "      <td>-0.042057</td>\n",
       "      <td>-0.777582</td>\n",
       "      <td>-0.052806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.309700</td>\n",
       "      <td>-2.702552</td>\n",
       "      <td>0.533542</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>0.622271</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>-0.789617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>-1.163636</td>\n",
       "      <td>-1.045919</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-0.517723</td>\n",
       "      <td>-0.283761</td>\n",
       "      <td>0.034922</td>\n",
       "      <td>1.101138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.309700</td>\n",
       "      <td>-0.164153</td>\n",
       "      <td>0.240776</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>1.595420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>1.187948</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-0.927380</td>\n",
       "      <td>1.601528</td>\n",
       "      <td>-0.748930</td>\n",
       "      <td>1.386680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.498841</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>-0.590548</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>-0.189015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.071015</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-1.005409</td>\n",
       "      <td>-0.456406</td>\n",
       "      <td>-0.742790</td>\n",
       "      <td>-0.326573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.498841</td>\n",
       "      <td>-0.587219</td>\n",
       "      <td>-0.481692</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-3.502058</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>-1.335883</td>\n",
       "      <td>-0.789617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>-1.163636</td>\n",
       "      <td>-1.045919</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>1.676865</td>\n",
       "      <td>0.904040</td>\n",
       "      <td>-0.491057</td>\n",
       "      <td>-0.812289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31007</th>\n",
       "      <td>-1.122878</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>0.076099</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>-1.373440</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>0.622271</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>0.046759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.071015</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>-1.200484</td>\n",
       "      <td>0.310140</td>\n",
       "      <td>0.413546</td>\n",
       "      <td>0.176805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31008</th>\n",
       "      <td>-1.122878</td>\n",
       "      <td>-0.587219</td>\n",
       "      <td>-1.174059</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>-1.373440</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>-1.335883</td>\n",
       "      <td>-0.789617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>-1.163636</td>\n",
       "      <td>0.071015</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-1.190730</td>\n",
       "      <td>0.289422</td>\n",
       "      <td>-0.179972</td>\n",
       "      <td>-1.089000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31009</th>\n",
       "      <td>-1.122878</td>\n",
       "      <td>-0.446197</td>\n",
       "      <td>-0.486981</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>2.561865</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>-1.335883</td>\n",
       "      <td>-0.789617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>-1.163636</td>\n",
       "      <td>-1.045919</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>-1.661825</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>-1.395558</td>\n",
       "      <td>-0.608334</td>\n",
       "      <td>-0.249557</td>\n",
       "      <td>-0.620947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31010</th>\n",
       "      <td>-1.122878</td>\n",
       "      <td>-0.164153</td>\n",
       "      <td>-0.225371</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>-1.341695</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>0.039313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>1.187948</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>-1.661825</td>\n",
       "      <td>-0.721294</td>\n",
       "      <td>-0.790827</td>\n",
       "      <td>-0.725733</td>\n",
       "      <td>0.145439</td>\n",
       "      <td>-0.317742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31011</th>\n",
       "      <td>-0.312019</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>0.063108</td>\n",
       "      <td>-0.186118</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>-0.390341</td>\n",
       "      <td>0.622271</td>\n",
       "      <td>-0.210163</td>\n",
       "      <td>-1.335883</td>\n",
       "      <td>-0.747426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>-1.163636</td>\n",
       "      <td>-1.045919</td>\n",
       "      <td>-0.301761</td>\n",
       "      <td>0.601748</td>\n",
       "      <td>1.386397</td>\n",
       "      <td>-0.654275</td>\n",
       "      <td>-0.152550</td>\n",
       "      <td>-0.448078</td>\n",
       "      <td>0.276892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31012 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
       "0     -0.312019  1.528114 -0.648514 -0.186118 -1.373440 -0.390341  0.622271   \n",
       "1      1.309700 -2.702552  0.533542 -0.186118  0.728099 -0.390341  0.622271   \n",
       "2      1.309700 -0.164153  0.240776 -0.186118  0.728099 -0.390341 -1.341695   \n",
       "3      0.498841  0.681981 -0.590548 -0.186118  0.728099 -0.390341 -1.341695   \n",
       "4      0.498841 -0.587219 -0.481692 -0.186118  0.728099 -0.390341 -3.502058   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "31007 -1.122878  0.681981  0.076099 -0.186118 -1.373440 -0.390341  0.622271   \n",
       "31008 -1.122878 -0.587219 -1.174059 -0.186118 -1.373440 -0.390341 -1.341695   \n",
       "31009 -1.122878 -0.446197 -0.486981 -0.186118  0.728099  2.561865 -1.341695   \n",
       "31010 -1.122878 -0.164153 -0.225371 -0.186118  0.728099 -0.390341 -1.341695   \n",
       "31011 -0.312019  0.681981  0.063108 -0.186118  0.728099 -0.390341  0.622271   \n",
       "\n",
       "            f_7       f_8       f_9  ...      f_11      f_12      f_13  \\\n",
       "0     -0.210163  0.748568  1.558192  ...  0.408986  0.859375  1.187948   \n",
       "1     -0.210163  0.748568 -0.789617  ...  0.408986 -1.163636 -1.045919   \n",
       "2     -0.210163  0.748568  1.595420  ...  0.408986  0.859375  1.187948   \n",
       "3     -0.210163  0.748568 -0.189015  ...  0.408986  0.859375  0.071015   \n",
       "4     -0.210163 -1.335883 -0.789617  ...  0.408986 -1.163636 -1.045919   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "31007 -0.210163  0.748568  0.046759  ...  0.408986  0.859375  0.071015   \n",
       "31008 -0.210163 -1.335883 -0.789617  ...  0.408986 -1.163636  0.071015   \n",
       "31009 -0.210163 -1.335883 -0.789617  ...  0.408986 -1.163636 -1.045919   \n",
       "31010 -0.210163  0.748568  0.039313  ...  0.408986  0.859375  1.187948   \n",
       "31011 -0.210163 -1.335883 -0.747426  ...  0.408986 -1.163636 -1.045919   \n",
       "\n",
       "           f_14      f_15      f_16      f_17      f_18      f_19      f_20  \n",
       "0     -0.301761  0.601748 -0.721294 -1.229745 -0.042057 -0.777582 -0.052806  \n",
       "1     -0.301761  0.601748  1.386397 -0.517723 -0.283761  0.034922  1.101138  \n",
       "2     -0.301761  0.601748  1.386397 -0.927380  1.601528 -0.748930  1.386680  \n",
       "3     -0.301761  0.601748  1.386397 -1.005409 -0.456406 -0.742790 -0.326573  \n",
       "4     -0.301761  0.601748 -0.721294  1.676865  0.904040 -0.491057 -0.812289  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "31007 -0.301761  0.601748 -0.721294 -1.200484  0.310140  0.413546  0.176805  \n",
       "31008 -0.301761  0.601748  1.386397 -1.190730  0.289422 -0.179972 -1.089000  \n",
       "31009 -0.301761 -1.661825 -0.721294 -1.395558 -0.608334 -0.249557 -0.620947  \n",
       "31010 -0.301761 -1.661825 -0.721294 -0.790827 -0.725733  0.145439 -0.317742  \n",
       "31011 -0.301761  0.601748  1.386397 -0.654275 -0.152550 -0.448078  0.276892  \n",
       "\n",
       "[31012 rows x 21 columns]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "inputs_torch = torch.tensor(inputs.values)\n",
    "labels_torch = torch.tensor(labels.values)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6675, 0.3391, 0.6481,  ..., 0.3050, 0.6674, 0.3166])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output_pred = model(inputs_torch)\n",
    "output_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc  \n",
    "fpr_0, tpr_0, _ = roc_curve(labels_torch, output_pred)  \n",
    "roc_auc_0 = auc(fpr_0, tpr_0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc  \n",
    "fpr_1, tpr_1, _ = roc_curve(labels_torch, output_pred)  \n",
    "roc_auc_1 = auc(fpr_1, tpr_1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc  \n",
    "fpr_2, tpr_2, _ = roc_curve(labels_torch, output_pred)  \n",
    "roc_auc_2 = auc(fpr_2, tpr_2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc  \n",
    "fpr_3, tpr_3, _ = roc_curve(labels_torch, output_pred)  \n",
    "roc_auc_3 = auc(fpr_3, tpr_3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc  \n",
    "fpr_4, tpr_4, _ = roc_curve(labels_torch, output_pred)  \n",
    "roc_auc_4 = auc(fpr_4, tpr_4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc  \n",
    "fpr_5, tpr_5, _ = roc_curve(labels_torch, output_pred)  \n",
    "roc_auc_5 = auc(fpr_5, tpr_5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "plt.figure()  \n",
    "lw = 2  \n",
    "#plt.plot(fpr_0, tpr_0, color='darkorange', lw=lw, label='mask_0 (area = %0.2f)' % roc_auc_0)  \n",
    "plt.plot(fpr_1, tpr_1, color='navy', lw=lw, label='mask_10 (area = %0.2f)' % roc_auc_1)\n",
    "#plt.plot(fpr_2, tpr_2, color='red', lw=lw, label='mask_20 (area = %0.2f)' % roc_auc_2)\n",
    "#plt.plot(fpr_3, tpr_3, color='yellow', lw=lw, label='mask_30 (area = %0.2f)' % roc_auc_3)\n",
    "#plt.plot(fpr_4, tpr_4, color='green', lw=lw, label='mask_40 (area = %0.2f)' % roc_auc_4)\n",
    "#plt.plot(fpr_5, tpr_5, color='darkblue', lw=lw, label='mask_50 (area = %0.2f)' % roc_auc_5)\n",
    "#plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')  \n",
    "plt.xlim([0.0, 1.0])  \n",
    "plt.ylim([0.0, 1.0])  \n",
    "plt.xlabel('False Positive Rate')  \n",
    "plt.ylabel('True Positive Rate')  \n",
    "plt.title('Receiver operating characteristic example')  \n",
    "plt.legend(loc=\"lower right\") \n",
    "img_pth = \"C:\\\\Users\\\\A200274027\\\\vscode\\\\pix\\\\home\\\\playground\\\\ssl_sample\\\\outputs\\\\wanb_export\\\\roc\\exp_4\\\\noise_10.png\"\n",
    "plt.savefig(img_pth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pix_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
